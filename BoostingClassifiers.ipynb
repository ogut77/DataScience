{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled71.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVqslZxYtqiHWLvows0qem",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogut77/DataScience/blob/main/BoostingClassifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Optimization Techniques and Libraries"
      ],
      "metadata": {
        "id": "IrgV4xyWYWoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " What Is Hyperparameter Tuning?\n",
        "\n",
        "Hyperparameter tuning is the process of tuning the parameters present as the tuples while we build machine learning models. These parameters are defined by us which can be manipulated according to programmer wish. Machine learning algorithms never learn these parameters. These are tuned so that we could get good performance by the model. Hyperparameter tuning aims to find such parameters where the performance of the model is highest or where the model performance is best and the error rate is least. "
      ],
      "metadata": {
        "id": "ajmd__rSEsLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What Steps To Follow For Hyper Parameter Tuning?\n",
        "\n",
        "1)Select the type of model we want to use \n",
        "\n",
        "2) Check what are the parameters of the model.\n",
        "\n",
        "3)Select the methods for searching the hyperparameter\n",
        "\n",
        "4) Select the cross-validation approach\n",
        "\n",
        "5) Evaluate the model using the score"
      ],
      "metadata": {
        "id": "8AAPhbXYFPjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several methods for hyperparameter tuning in machine learning, including:\n",
        "\n",
        "Grid Search: Grid search involves defining a range of hyperparameter values and training the model on all possible combinations of these values. The performance of the model is evaluated on a validation set, and the best combination of hyperparameters is selected based on the highest performance.\n",
        "\n",
        "Random Search: Random search involves defining a range of hyperparameter values and randomly sampling combinations of these values. The performance of the model is evaluated on a validation set, and the best combination of hyperparameters is selected based on the highest performance.\n",
        "\n",
        "Bayesian Optimization: Bayesian optimization is a more sophisticated method for hyperparameter tuning. It involves constructing a probabilistic model of the objective function (i.e., the performance metric) and using this model to guide the search for optimal hyperparameters. Bayesian optimization is particularly useful when the search space for hyperparameters is large and complex.\n",
        "\n",
        "Gradient-based Optimization: Gradient-based optimization involves optimizing the hyperparameters using gradient descent. This method is more computationally expensive than other methods, but it can be effective for complex models and high-dimensional hyperparameter spaces.\n",
        "\n",
        "Ensemble-based Optimization: Ensemble-based optimization involves training multiple models with different hyperparameter settings and combining their predictions to make a final prediction. This method can be effective when the performance of individual models is highly variable across different hyperparameter settings.\n",
        "\n",
        "Overall, the choice of hyperparameter tuning method depends on the specific problem and the size and complexity of the hyperparameter space."
      ],
      "metadata": {
        "id": "cIKagXKHF2KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for Jupyter-book, we copy data from GitHub, locally, to save Internet traffic,\n",
        "# you can specify the data/ folder from the root of your cloned\n",
        "# https://github.com/Yorko/mlcourse.ai repo, to save Internet traffic\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "from matplotlib import pyplot as plt\n",
        "DATA_PATH = \"https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/\"\n",
        "df = pd.read_csv(DATA_PATH + \"telecom_churn.csv\")\n",
        "\n",
        "df[\"International plan\"] = pd.factorize(df[\"International plan\"])[0]\n",
        "df[\"Voice mail plan\"] = pd.factorize(df[\"Voice mail plan\"])[0]\n",
        "df[\"Churn\"] = df[\"Churn\"].astype(\"int\")\n",
        "states = df[\"State\"]\n",
        "y = df[\"Churn\"]\n",
        "X=df.drop([\"State\", \"Churn\"], axis=1)\n"
      ],
      "metadata": {
        "id": "EZdL1N4MZqZF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "hm9ZMVW9aJNh",
        "outputId": "9879738a-69ec-4e9e-e5f5-365c23dc3488"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Account length  Area code  International plan  Voice mail plan  \\\n",
              "0                128        415                   0                0   \n",
              "1                107        415                   0                0   \n",
              "2                137        415                   0                1   \n",
              "3                 84        408                   1                1   \n",
              "4                 75        415                   1                1   \n",
              "...              ...        ...                 ...              ...   \n",
              "3328             192        415                   0                0   \n",
              "3329              68        415                   0                1   \n",
              "3330              28        510                   0                1   \n",
              "3331             184        510                   1                1   \n",
              "3332              74        415                   0                0   \n",
              "\n",
              "      Number vmail messages  Total day minutes  Total day calls  \\\n",
              "0                        25              265.1              110   \n",
              "1                        26              161.6              123   \n",
              "2                         0              243.4              114   \n",
              "3                         0              299.4               71   \n",
              "4                         0              166.7              113   \n",
              "...                     ...                ...              ...   \n",
              "3328                     36              156.2               77   \n",
              "3329                      0              231.1               57   \n",
              "3330                      0              180.8              109   \n",
              "3331                      0              213.8              105   \n",
              "3332                     25              234.4              113   \n",
              "\n",
              "      Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
              "0                45.07              197.4               99             16.78   \n",
              "1                27.47              195.5              103             16.62   \n",
              "2                41.38              121.2              110             10.30   \n",
              "3                50.90               61.9               88              5.26   \n",
              "4                28.34              148.3              122             12.61   \n",
              "...                ...                ...              ...               ...   \n",
              "3328             26.55              215.5              126             18.32   \n",
              "3329             39.29              153.4               55             13.04   \n",
              "3330             30.74              288.8               58             24.55   \n",
              "3331             36.35              159.6               84             13.57   \n",
              "3332             39.85              265.9               82             22.60   \n",
              "\n",
              "      Total night minutes  Total night calls  Total night charge  \\\n",
              "0                   244.7                 91               11.01   \n",
              "1                   254.4                103               11.45   \n",
              "2                   162.6                104                7.32   \n",
              "3                   196.9                 89                8.86   \n",
              "4                   186.9                121                8.41   \n",
              "...                   ...                ...                 ...   \n",
              "3328                279.1                 83               12.56   \n",
              "3329                191.3                123                8.61   \n",
              "3330                191.9                 91                8.64   \n",
              "3331                139.2                137                6.26   \n",
              "3332                241.4                 77               10.86   \n",
              "\n",
              "      Total intl minutes  Total intl calls  Total intl charge  \\\n",
              "0                   10.0                 3               2.70   \n",
              "1                   13.7                 3               3.70   \n",
              "2                   12.2                 5               3.29   \n",
              "3                    6.6                 7               1.78   \n",
              "4                   10.1                 3               2.73   \n",
              "...                  ...               ...                ...   \n",
              "3328                 9.9                 6               2.67   \n",
              "3329                 9.6                 4               2.59   \n",
              "3330                14.1                 6               3.81   \n",
              "3331                 5.0                10               1.35   \n",
              "3332                13.7                 4               3.70   \n",
              "\n",
              "      Customer service calls  \n",
              "0                          1  \n",
              "1                          1  \n",
              "2                          0  \n",
              "3                          2  \n",
              "4                          3  \n",
              "...                      ...  \n",
              "3328                       2  \n",
              "3329                       3  \n",
              "3330                       2  \n",
              "3331                       2  \n",
              "3332                       0  \n",
              "\n",
              "[3333 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32901b19-b7cb-47b6-b8c1-37f9ad7e5eda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Account length</th>\n",
              "      <th>Area code</th>\n",
              "      <th>International plan</th>\n",
              "      <th>Voice mail plan</th>\n",
              "      <th>Number vmail messages</th>\n",
              "      <th>Total day minutes</th>\n",
              "      <th>Total day calls</th>\n",
              "      <th>Total day charge</th>\n",
              "      <th>Total eve minutes</th>\n",
              "      <th>Total eve calls</th>\n",
              "      <th>Total eve charge</th>\n",
              "      <th>Total night minutes</th>\n",
              "      <th>Total night calls</th>\n",
              "      <th>Total night charge</th>\n",
              "      <th>Total intl minutes</th>\n",
              "      <th>Total intl calls</th>\n",
              "      <th>Total intl charge</th>\n",
              "      <th>Customer service calls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>107</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>137</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84</td>\n",
              "      <td>408</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>415</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3328</th>\n",
              "      <td>192</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>156.2</td>\n",
              "      <td>77</td>\n",
              "      <td>26.55</td>\n",
              "      <td>215.5</td>\n",
              "      <td>126</td>\n",
              "      <td>18.32</td>\n",
              "      <td>279.1</td>\n",
              "      <td>83</td>\n",
              "      <td>12.56</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "      <td>2.67</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3329</th>\n",
              "      <td>68</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>231.1</td>\n",
              "      <td>57</td>\n",
              "      <td>39.29</td>\n",
              "      <td>153.4</td>\n",
              "      <td>55</td>\n",
              "      <td>13.04</td>\n",
              "      <td>191.3</td>\n",
              "      <td>123</td>\n",
              "      <td>8.61</td>\n",
              "      <td>9.6</td>\n",
              "      <td>4</td>\n",
              "      <td>2.59</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3330</th>\n",
              "      <td>28</td>\n",
              "      <td>510</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>180.8</td>\n",
              "      <td>109</td>\n",
              "      <td>30.74</td>\n",
              "      <td>288.8</td>\n",
              "      <td>58</td>\n",
              "      <td>24.55</td>\n",
              "      <td>191.9</td>\n",
              "      <td>91</td>\n",
              "      <td>8.64</td>\n",
              "      <td>14.1</td>\n",
              "      <td>6</td>\n",
              "      <td>3.81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>184</td>\n",
              "      <td>510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>213.8</td>\n",
              "      <td>105</td>\n",
              "      <td>36.35</td>\n",
              "      <td>159.6</td>\n",
              "      <td>84</td>\n",
              "      <td>13.57</td>\n",
              "      <td>139.2</td>\n",
              "      <td>137</td>\n",
              "      <td>6.26</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>74</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>234.4</td>\n",
              "      <td>113</td>\n",
              "      <td>39.85</td>\n",
              "      <td>265.9</td>\n",
              "      <td>82</td>\n",
              "      <td>22.60</td>\n",
              "      <td>241.4</td>\n",
              "      <td>77</td>\n",
              "      <td>10.86</td>\n",
              "      <td>13.7</td>\n",
              "      <td>4</td>\n",
              "      <td>3.70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3333 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32901b19-b7cb-47b6-b8c1-37f9ad7e5eda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32901b19-b7cb-47b6-b8c1-37f9ad7e5eda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32901b19-b7cb-47b6-b8c1-37f9ad7e5eda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "6ct1B7Xw1frV",
        "outputId": "4c7e947d-62b4-443a-9413-6694a302883e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "3328    0\n",
              "3329    0\n",
              "3330    0\n",
              "3331    0\n",
              "3332    0\n",
              "Name: Churn, Length: 3333, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into 2 parts:test and train\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=17\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "aC4sGAvybIGe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decison Tree\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "tree = DecisionTreeClassifier(random_state=17)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "tree_pred = tree.predict(X_test)\n",
        "print(accuracy_score(y_test, tree_pred))\n",
        "print(confusion_matrix(y_test, tree_pred)) \n",
        "sum(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caDTFnXIb9Kn",
        "outputId": "635a2818-300b-4f40-8781-1079cea098ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.92\n",
            "[[827  40]\n",
            " [ 40  93]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(random_state=17 )\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "\n",
        "forest_pred = forest.predict(X_test)\n",
        "print(accuracy_score(y_test, forest_pred) )\n",
        "print(confusion_matrix(y_test, forest_pred)) \n",
        "sum(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "eqqgQ351dStx",
        "outputId": "91236e41-d74a-4f5e-dce5-4f86826ff6f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f59fd513c198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mforest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforest_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(random_state=17)\n",
        "model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "xgb_pred = model.predict(X_test)\n",
        "print(accuracy_score(y_test, xgb_pred))\n",
        "print(confusion_matrix(y_test, xgb_pred)) \n",
        "sum(y_test)"
      ],
      "metadata": {
        "id": "g5ar8WG6-q_4",
        "outputId": "9cc34e10-9945-4d88-a15e-1ba25b462876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.951\n",
            "[[858   9]\n",
            " [ 40  93]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Light GBM\n",
        "import lightgbm as lgb\n",
        "lgb_model = lgb.LGBMClassifier(random_state=17)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "print(accuracy_score(y_test, lgb_model.predict(X_test)))\n",
        "print(confusion_matrix(y_test, lgb_model.predict(X_test))) \n"
      ],
      "metadata": {
        "id": "sDYQOsNJClI6",
        "outputId": "bf8f5764-ff7f-4284-87b4-a39db91a4150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.956\n",
            "[[861   6]\n",
            " [ 38  95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbm_model = GradientBoostingClassifier(random_state=17)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "print(accuracy_score(y_test, gbm_model.predict(X_test)))\n",
        "print(confusion_matrix(y_test, gbm_model.predict(X_test))) \n"
      ],
      "metadata": {
        "id": "7uzEf6HPB8q4",
        "outputId": "bcebafc6-81ac-429f-b79d-81dd10b8aa71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.954\n",
            "[[858   9]\n",
            " [ 37  96]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ada Boost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada = AdaBoostClassifier(random_state=17)\n",
        "ada.fit(X_train, y_train)\n",
        "print(accuracy_score(y_test, ada.predict(X_test)))\n",
        "print(confusion_matrix(y_test, ada.predict(X_test)))"
      ],
      "metadata": {
        "id": "JR2Z8O8EYi0N",
        "outputId": "05129a88-173f-4732-91a1-443dc9d9342a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.874\n",
            "[[823  44]\n",
            " [ 82  51]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Number of feaures(input) for X\n",
        " X_train.shape[1]"
      ],
      "metadata": {
        "id": "AzXFG5B-6gbD",
        "outputId": "64ac4b80-8f72-466c-b26f-000327e49658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Search CV"
      ],
      "metadata": {
        "id": "jL8o3u5DHjrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "t0=time()\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "xgb_params = {\"max_depth\": range(5, X_train.shape[1],3), \"max_features\": range(5, X_train.shape[1],3)}\n",
        "\n",
        "forest = RandomForestClassifier(random_state=17 )\n",
        "forest_grid = RandomizedSearchCV(forest, xgb_params, cv=3, n_jobs=-1, verbose=True)\n",
        "forest_grid.fit(X_train,y_train)\n",
        "\n",
        "print(forest_grid.best_params_, forest_grid.best_score_)\n",
        "print(accuracy_score(y_test, forest_grid.predict(X_test)))\n",
        "t1=time()\n",
        "print('Time is ' +str(t1-t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQVMpWzFHvvn",
        "outputId": "8c2a6aad-cd56-4cc6-fb3a-87d260d8c6a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "{'max_features': 8, 'max_depth': 14} 0.9455643671581976\n",
            "0.953\n",
            "Time is 33.64668297767639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search CV"
      ],
      "metadata": {
        "id": "QMzEiMGHHzec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We can not choose model based on test data.\n",
        "#Random Forest CV\n",
        "from time import time\n",
        "t0=time()\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "xgb_params = {\"max_depth\": range(5, X_train.shape[1],3), \"max_features\": range(5, X_train.shape[1],3)}\n",
        "\n",
        "forest = RandomForestClassifier(random_state=17 )\n",
        "forest_grid = GridSearchCV(forest, forest_params, cv=3, n_jobs=-1, verbose=True)\n",
        "forest_grid.fit(X_train,y_train)\n",
        "\n",
        "print(forest_grid.best_params_, forest_grid.best_score_)\n",
        "print(accuracy_score(y_test, forest_grid.predict(X_test)))\n",
        "t1=time()\n",
        "print('Time is ' +str(t1-t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1leXRk6O-Hm",
        "outputId": "9d7b6daf-05f3-4b3e-932d-4b6860375ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
            "{'max_depth': 17, 'max_features': 8} 0.946421265187332\n",
            "0.954\n",
            "Time is 44.77019786834717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest with best parameters give same accuracy result  with forest_grid.predict(X_test)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(random_state=17,max_depth=17,max_features=8)\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "\n",
        "forest_pred = forest.predict(X_test)\n",
        "print(accuracy_score(y_test, forest_pred) )"
      ],
      "metadata": {
        "id": "F8Du8TFxTZFu",
        "outputId": "632cddde-d3dd-461c-e13f-b34d39b6ca85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "t0=time()\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "xgb_params = {\"max_depth\": range(5, X_train.shape[1],3), \"max_features\": range(5, X_train.shape[1],3)}\n",
        "xgbm = XGBClassifier(random_state=17)\n",
        "xgb_grid = GridSearchCV(xgbm, xgb_params , cv=3, n_jobs=-1, verbose=True)\n",
        "xgb_grid.fit(X_train,y_train)\n",
        "\n",
        "print(xgb_grid.best_params_, xgb_grid.best_score_)\n",
        "print(accuracy_score(y_test, xgb_grid.predict(X_test)))\n",
        "t1=time()\n",
        "print('Time is ' +str(t1-t0))\n"
      ],
      "metadata": {
        "id": "O1X3UbjSfNGV",
        "outputId": "dc7f9adf-3ad6-43ef-c56f-f8a6fca04d2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
            "{'max_depth': 5, 'max_features': 5} 0.9481361640744673\n",
            "0.955\n",
            "Time is 28.817909479141235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Light GBM CV\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "from time import time\n",
        "t0=time()\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "lgb_params = {\"max_depth\": range(5, X_train.shape[1],3), \"max_features\": range(5, X_train.shape[1],3)}\n",
        "lgbm = lgb.LGBMClassifier(random_state=17)\n",
        "lgb_grid = GridSearchCV(lgbm, lgb_params , cv=3, n_jobs=-1, verbose=True)\n",
        "lgb_grid.fit(X_train,y_train)\n",
        "\n",
        "print(lgb_grid.best_params_, lgb_grid.best_score_)\n",
        "print(accuracy_score(y_test,lgb_grid.predict(X_test)))\n",
        "t1=time()\n",
        "print('Time is ' +str(t1-t0))"
      ],
      "metadata": {
        "id": "vDoJ0GG2fWg6",
        "outputId": "ef276bf5-7223-4676-e823-dccf73dee8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
            "{'max_depth': 17, 'max_features': 5} 0.9558526576521436\n",
            "0.954\n",
            "Time is 10.507242679595947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Based CV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "lgb_params = {\"max_depth\": range(5, X_train.shape[1],3), \"max_features\": range(5, X_train.shape[1],3)}\n",
        "gbm_model = GradientBoostingClassifier(random_state=17)\n",
        "gbm_grid = GridSearchCV(gbm_model , lgb_params , cv=3, n_jobs=-1, verbose=True)\n",
        "gbm_grid.fit(X_train,y_train)\n",
        "\n",
        "print(gbm_grid.best_params_, gbm_grid.best_score_)\n",
        "print(accuracy_score(y_test,gbm_grid.predict(X_test)))\n",
        "t1=time()\n",
        "print('Time is ' +str(t1-t0))\n",
        "\n"
      ],
      "metadata": {
        "id": "oh3PmdkTfYGi",
        "outputId": "76d72760-79a9-48aa-ec1c-d3b82e3cd5d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
            "{'max_depth': 8, 'max_features': 11} 0.9502784091473037\n",
            "0.951\n",
            "Time is 247.14879035949707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Which model give  the highest CV  \n",
        "#and what is the accuracy result on test data?\n"
      ],
      "metadata": {
        "id": "4ovjPHwuQWux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the popular libraries for hyper paramater optimization are optuna or hyperopt . You can check following link for comparison of two methods. \n",
        "\n",
        "https://neptune.ai/blog/optuna-vs-hyperopt\n",
        "\n",
        "\n",
        "By default, Optuna implements a Bayesian optimization algorithm named Tree-structured Parzen Estimator(TPE) but it can be easily switched to other existing algorithms in the package. The some of the other algorithms used by Optuna  are Grid Search, Random Search, CMA-ES based algortihm, Quasi Monte Carlo sampling algorithm  and Genetic Algorithm."
      ],
      "metadata": {
        "id": "SSkHV3F9OWjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "id": "FlZybpVuUw1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimize (x - 2) ** 2 if x is between ( -10, 10)\n",
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    x = trial.suggest_float('x', -10, 10)\n",
        "    return (x - 2) ** 2\n",
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(study.best_params) # E.g. {'x': 2.002108042}\n",
        "print(study.best_trial)"
      ],
      "metadata": {
        "id": "aEdxFHEbbFyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximize (x - 2) ** 2 if x is between ( -10, 10)\n",
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    x = trial.suggest_float('x', -10, 10)\n",
        "    return (x - 2) ** 2\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")#We specify this is maximization problem\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(study.best_params) # E.g. {'x':- 9.992108042}\n",
        "print(study.best_trial)"
      ],
      "metadata": {
        "id": "GlM7rvlFWKCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "import sklearn.datasets\n",
        "import sklearn.ensemble\n",
        "import sklearn.model_selection\n",
        "import sklearn.svm\n",
        "\n",
        "\n",
        "# FYI: Objective functions can take additional arguments\n",
        "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
        "def objective(trial):\n",
        "    x, y = X_train,y_train\n",
        "\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"Random Forest\",\"XGBoost\", \"LightGBM\",\"GradientBoostingClassifier\" ])\n",
        "    if classifier_name == \"Random Forest\":\n",
        "         from sklearn.ensemble import RandomForestClassifier\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
        "         classifier_obj = sklearn.ensemble.RandomForestClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "         \n",
        "\n",
        "    elif classifier_name == \"XGBoost\":\n",
        "         from xgboost import XGBClassifier\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
        "         classifier_obj = XGBClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "         \n",
        "\n",
        "    elif classifier_name == \"LightGBM\":\n",
        "         import lightgbm as lgb\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
        "         classifier_obj = lgb.LGBMClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "       \n",
        "       \n",
        "    else:\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,X_train.shape[1])\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
        "         classifier_obj = sklearn.ensemble.GradientBoostingClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "         \n",
        "\n",
        "    accuracy=sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3).mean()\n",
        "   \n",
        "    return accuracy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "    print(study.best_trial)"
      ],
      "metadata": {
        "id": "fkFEMF1VY6zF",
        "outputId": "88f8d3df-b468-420c-bf42-df737a198feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-03-16 11:06:13,482]\u001b[0m A new study created in memory with name: no-name-228daac0-7fa1-47e9-8ddc-9480046e17ec\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:17,121]\u001b[0m Trial 0 finished with value: 0.9468497142018993 and parameters: {'classifier': 'XGBoost', 'max_depth': 8, 'max_features': 6}. Best is trial 0 with value: 0.9468497142018993.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:18,424]\u001b[0m Trial 1 finished with value: 0.9481334070023015 and parameters: {'classifier': 'XGBoost', 'max_depth': 7, 'max_features': 5}. Best is trial 1 with value: 0.9481334070023015.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:19,646]\u001b[0m Trial 2 finished with value: 0.9361329746933861 and parameters: {'classifier': 'Random Forest', 'max_depth': 5, 'max_features': 8}. Best is trial 1 with value: 0.9481334070023015.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:20,852]\u001b[0m Trial 3 finished with value: 0.9485646130890347 and parameters: {'classifier': 'XGBoost', 'max_depth': 12, 'max_features': 7}. Best is trial 3 with value: 0.9485646130890347.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:23,893]\u001b[0m Trial 4 finished with value: 0.9489919592747356 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 8, 'max_features': 12}. Best is trial 4 with value: 0.9489919592747356.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:25,115]\u001b[0m Trial 5 finished with value: 0.9477071636454669 and parameters: {'classifier': 'XGBoost', 'max_depth': 15, 'max_features': 4}. Best is trial 4 with value: 0.9489919592747356.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:25,843]\u001b[0m Trial 6 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 9}. Best is trial 6 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:30,883]\u001b[0m Trial 7 finished with value: 0.9301324828317116 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 18, 'max_features': 14}. Best is trial 6 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:31,404]\u001b[0m Trial 8 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 5}. Best is trial 8 with value: 0.9549957596230091.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:31,787]\u001b[0m Trial 9 finished with value: 0.9528535145501728 and parameters: {'classifier': 'LightGBM', 'max_depth': 7, 'max_features': 11}. Best is trial 8 with value: 0.9549957596230091.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:32,331]\u001b[0m Trial 10 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 18}. Best is trial 8 with value: 0.9549957596230091.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:32,863]\u001b[0m Trial 11 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 17}. Best is trial 8 with value: 0.9549957596230091.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:33,406]\u001b[0m Trial 12 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 2}. Best is trial 8 with value: 0.9549957596230091.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:33,552]\u001b[0m Trial 13 finished with value: 0.9237068504420689 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 18}. Best is trial 8 with value: 0.9549957596230091.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:36,351]\u001b[0m Trial 14 finished with value: 0.9442784687000625 and parameters: {'classifier': 'Random Forest', 'max_depth': 16, 'max_features': 15}. Best is trial 8 with value: 0.9549957596230091.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:36,861]\u001b[0m Trial 15 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 2}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:37,376]\u001b[0m Trial 16 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 2}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:37,899]\u001b[0m Trial 17 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 4}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:40,460]\u001b[0m Trial 18 finished with value: 0.9219875402394683 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 10, 'max_features': 2}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:41,531]\u001b[0m Trial 19 finished with value: 0.9421312608973277 and parameters: {'classifier': 'Random Forest', 'max_depth': 10, 'max_features': 4}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:42,064]\u001b[0m Trial 20 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 6}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:42,606]\u001b[0m Trial 21 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:43,143]\u001b[0m Trial 22 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:43,673]\u001b[0m Trial 23 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 10}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:44,231]\u001b[0m Trial 24 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:44,765]\u001b[0m Trial 25 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:45,311]\u001b[0m Trial 26 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:50,481]\u001b[0m Trial 27 finished with value: 0.9331316259336825 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:52,546]\u001b[0m Trial 28 finished with value: 0.9434204678420617 and parameters: {'classifier': 'Random Forest', 'max_depth': 11, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:53,780]\u001b[0m Trial 29 finished with value: 0.9477071636454669 and parameters: {'classifier': 'XGBoost', 'max_depth': 16, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:54,009]\u001b[0m Trial 30 finished with value: 0.9434204678420617 and parameters: {'classifier': 'LightGBM', 'max_depth': 4, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:54,552]\u001b[0m Trial 31 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:55,089]\u001b[0m Trial 32 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:55,562]\u001b[0m Trial 33 finished with value: 0.9511375128341709 and parameters: {'classifier': 'LightGBM', 'max_depth': 9, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:56,796]\u001b[0m Trial 34 finished with value: 0.9477071636454669 and parameters: {'classifier': 'XGBoost', 'max_depth': 17, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:57,329]\u001b[0m Trial 35 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 12}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:06:59,308]\u001b[0m Trial 36 finished with value: 0.9434204678420617 and parameters: {'classifier': 'Random Forest', 'max_depth': 12, 'max_features': 10}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:00,567]\u001b[0m Trial 37 finished with value: 0.9477071636454669 and parameters: {'classifier': 'XGBoost', 'max_depth': 16, 'max_features': 7}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:01,105]\u001b[0m Trial 38 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:02,472]\u001b[0m Trial 39 finished with value: 0.9459895076861659 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 5, 'max_features': 8}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:03,023]\u001b[0m Trial 40 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 12}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:03,553]\u001b[0m Trial 41 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:04,100]\u001b[0m Trial 42 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:04,636]\u001b[0m Trial 43 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:05,182]\u001b[0m Trial 44 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:05,726]\u001b[0m Trial 45 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 17}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:06,261]\u001b[0m Trial 46 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:06,712]\u001b[0m Trial 47 finished with value: 0.9507085124051705 and parameters: {'classifier': 'LightGBM', 'max_depth': 8, 'max_features': 9}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:11,759]\u001b[0m Trial 48 finished with value: 0.9301324828317116 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 18, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:13,011]\u001b[0m Trial 49 finished with value: 0.9485646130890347 and parameters: {'classifier': 'XGBoost', 'max_depth': 12, 'max_features': 17}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:13,346]\u001b[0m Trial 50 finished with value: 0.9507090638196036 and parameters: {'classifier': 'LightGBM', 'max_depth': 6, 'max_features': 12}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:13,881]\u001b[0m Trial 51 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:14,417]\u001b[0m Trial 52 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:14,966]\u001b[0m Trial 53 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:15,498]\u001b[0m Trial 54 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 18}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:16,046]\u001b[0m Trial 55 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 12}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:17,068]\u001b[0m Trial 56 finished with value: 0.9374166674937884 and parameters: {'classifier': 'Random Forest', 'max_depth': 16, 'max_features': 3}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:17,596]\u001b[0m Trial 57 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:18,148]\u001b[0m Trial 58 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:18,675]\u001b[0m Trial 59 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:24,239]\u001b[0m Trial 60 finished with value: 0.9365608722935201 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 13, 'max_features': 17}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:24,765]\u001b[0m Trial 61 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:25,314]\u001b[0m Trial 62 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:25,849]\u001b[0m Trial 63 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:26,396]\u001b[0m Trial 64 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:26,929]\u001b[0m Trial 65 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:27,074]\u001b[0m Trial 66 finished with value: 0.9237068504420689 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:29,998]\u001b[0m Trial 67 finished with value: 0.9425641212273602 and parameters: {'classifier': 'Random Forest', 'max_depth': 17, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:30,540]\u001b[0m Trial 68 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:31,779]\u001b[0m Trial 69 finished with value: 0.9477071636454669 and parameters: {'classifier': 'XGBoost', 'max_depth': 17, 'max_features': 5}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:32,326]\u001b[0m Trial 70 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:32,872]\u001b[0m Trial 71 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:33,432]\u001b[0m Trial 72 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 16}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:33,943]\u001b[0m Trial 73 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 10}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:34,494]\u001b[0m Trial 74 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:35,024]\u001b[0m Trial 75 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:35,572]\u001b[0m Trial 76 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:36,041]\u001b[0m Trial 77 finished with value: 0.9511375128341709 and parameters: {'classifier': 'LightGBM', 'max_depth': 9, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:40,949]\u001b[0m Trial 78 finished with value: 0.9395616696387904 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 18, 'max_features': 12}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:41,477]\u001b[0m Trial 79 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 17}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:41,671]\u001b[0m Trial 80 finished with value: 0.938704771609656 and parameters: {'classifier': 'LightGBM', 'max_depth': 3, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:42,213]\u001b[0m Trial 81 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 12}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:42,760]\u001b[0m Trial 82 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 12}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:43,299]\u001b[0m Trial 83 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 10}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:45,964]\u001b[0m Trial 84 finished with value: 0.9429920188274945 and parameters: {'classifier': 'Random Forest', 'max_depth': 17, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:46,493]\u001b[0m Trial 85 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 8}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:47,747]\u001b[0m Trial 86 finished with value: 0.9477071636454669 and parameters: {'classifier': 'XGBoost', 'max_depth': 16, 'max_features': 14}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:48,282]\u001b[0m Trial 87 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 6}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:48,826]\u001b[0m Trial 88 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 3}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:49,355]\u001b[0m Trial 89 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 6}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:49,893]\u001b[0m Trial 90 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 9}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:50,428]\u001b[0m Trial 91 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:50,976]\u001b[0m Trial 92 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 11}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:51,508]\u001b[0m Trial 93 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:52,048]\u001b[0m Trial 94 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 10}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:52,589]\u001b[0m Trial 95 finished with value: 0.9545678620228749 and parameters: {'classifier': 'LightGBM', 'max_depth': 18, 'max_features': 15}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:53,134]\u001b[0m Trial 96 finished with value: 0.9558526576521436 and parameters: {'classifier': 'LightGBM', 'max_depth': 17, 'max_features': 13}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:53,654]\u001b[0m Trial 97 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 7}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:57,002]\u001b[0m Trial 98 finished with value: 0.9494231653614688 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 10, 'max_features': 7}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:07:57,521]\u001b[0m Trial 99 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 9}. Best is trial 15 with value: 0.956281658081144.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenTrial(number=15, values=[0.956281658081144], datetime_start=datetime.datetime(2022, 3, 16, 11, 6, 36, 353952), datetime_complete=datetime.datetime(2022, 3, 16, 11, 6, 36, 861351), params={'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 2}, distributions={'classifier': CategoricalDistribution(choices=('Random Forest', 'XGBoost', 'LightGBM', 'GradientBoostingClassifier')), 'max_depth': IntUniformDistribution(high=18, low=2, step=1), 'max_features': IntUniformDistribution(high=18, low=2, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=15, state=TrialState.COMPLETE, value=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Best Model\n",
        "study.best_params"
      ],
      "metadata": {
        "id": "oKEwZpRvg2KC",
        "outputId": "407997ee-ca4f-4d35-dece-1abd2d35cd62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Light GBM Test Result with Best Parameters\n",
        "import lightgbm as lgb\n",
        "lgb_model = lgb.LGBMClassifier(random_state=17,max_depth=12,max_features=2)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "print(accuracy_score(y_test, lgb_model.predict(X_test)))\n",
        "print(confusion_matrix(y_test, lgb_model.predict(X_test))) "
      ],
      "metadata": {
        "id": "8C-dpY9Kadju",
        "outputId": "73cf9f4c-f6b8-47a1-af86-43e8f0c3c942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.956\n",
            "[[861   6]\n",
            " [ 38  95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Best Model Parameter to Test Data\n",
        "import optuna\n",
        "\n",
        "import sklearn.datasets\n",
        "import sklearn.ensemble\n",
        "import sklearn.model_selection\n",
        "import sklearn.svm\n",
        "\n",
        "\n",
        "# FYI: Objective functions can take additional arguments\n",
        "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
        "def objective(trial):\n",
        "    x, y = X_train,y_train\n",
        "\n",
        "    param = {\n",
        "        \"objective\": \"binary\",\n",
        "        \"verbosity\": -1,\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"max_dept\" :trial.suggest_int(\"max_depth\", 2, X_train.shape[1]),\n",
        "        \"max_features\" : trial.suggest_int(\"max_features\", 2,X_train.shape[1]),       \n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "    }\n",
        "    import lightgbm as lgb\n",
        "    classifier_obj = lgb.LGBMClassifier(random_state=17,**param)\n",
        "\n",
        "    accuracy=sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3).mean()\n",
        "   \n",
        "    return accuracy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "    print(study.best_trial)"
      ],
      "metadata": {
        "id": "8cmstdAHg46W",
        "outputId": "5d54a072-f640-4dfd-de1d-2d3d2cb34f51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-03-16 11:12:06,792]\u001b[0m A new study created in memory with name: no-name-a47f4c82-3889-4e92-a1d1-60fb6d06917b\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:09,487]\u001b[0m Trial 0 finished with value: 0.9005601267812064 and parameters: {'max_depth': 2, 'max_features': 8, 'num_leaves': 95, 'feature_fraction': 0.7356031545800499, 'bagging_fraction': 0.5842052165224785, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 0 with value: 0.9005601267812064.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:09,775]\u001b[0m Trial 1 finished with value: 0.8658430740692952 and parameters: {'max_depth': 11, 'max_features': 8, 'num_leaves': 24, 'feature_fraction': 0.9283871004799705, 'bagging_fraction': 0.46783616284560037, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 0 with value: 0.9005601267812064.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:10,854]\u001b[0m Trial 2 finished with value: 0.9451397780446623 and parameters: {'max_depth': 14, 'max_features': 2, 'num_leaves': 191, 'feature_fraction': 0.9806681762852808, 'bagging_fraction': 0.9422907016106667, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 2 with value: 0.9451397780446623.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:11,505]\u001b[0m Trial 3 finished with value: 0.8894182467447248 and parameters: {'max_depth': 15, 'max_features': 13, 'num_leaves': 202, 'feature_fraction': 0.8964430480772103, 'bagging_fraction': 0.549819323545624, 'bagging_freq': 2, 'min_child_samples': 80}. Best is trial 2 with value: 0.9451397780446623.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:12,266]\u001b[0m Trial 4 finished with value: 0.949848305889437 and parameters: {'max_depth': 13, 'max_features': 15, 'num_leaves': 44, 'feature_fraction': 0.666143399674501, 'bagging_fraction': 0.9601750570671235, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:12,508]\u001b[0m Trial 5 finished with value: 0.9108484172751524 and parameters: {'max_depth': 11, 'max_features': 14, 'num_leaves': 13, 'feature_fraction': 0.9079241887253282, 'bagging_fraction': 0.7577727943678482, 'bagging_freq': 3, 'min_child_samples': 82}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:12,807]\u001b[0m Trial 6 finished with value: 0.9219914001405004 and parameters: {'max_depth': 4, 'max_features': 5, 'num_leaves': 163, 'feature_fraction': 0.8036362370404047, 'bagging_fraction': 0.9404145193177936, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:13,477]\u001b[0m Trial 7 finished with value: 0.944280122943362 and parameters: {'max_depth': 17, 'max_features': 4, 'num_leaves': 48, 'feature_fraction': 0.9547815695723776, 'bagging_fraction': 0.8257352018310462, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:13,701]\u001b[0m Trial 8 finished with value: 0.9035598212976105 and parameters: {'max_depth': 5, 'max_features': 2, 'num_leaves': 163, 'feature_fraction': 0.4602443894699715, 'bagging_fraction': 0.47532427617728573, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:14,294]\u001b[0m Trial 9 finished with value: 0.9117025582321213 and parameters: {'max_depth': 9, 'max_features': 9, 'num_leaves': 65, 'feature_fraction': 0.4115565809295457, 'bagging_fraction': 0.7390687230230694, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:14,603]\u001b[0m Trial 10 finished with value: 0.9292772390458767 and parameters: {'max_depth': 8, 'max_features': 18, 'num_leaves': 117, 'feature_fraction': 0.5781861052520234, 'bagging_fraction': 0.9878065779696715, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:15,085]\u001b[0m Trial 11 finished with value: 0.9271333397297408 and parameters: {'max_depth': 14, 'max_features': 18, 'num_leaves': 249, 'feature_fraction': 0.6214641194177316, 'bagging_fraction': 0.868767025472468, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:16,560]\u001b[0m Trial 12 finished with value: 0.9391288093087579 and parameters: {'max_depth': 14, 'max_features': 13, 'num_leaves': 212, 'feature_fraction': 0.6529354540503292, 'bagging_fraction': 0.904095296855655, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:16,995]\u001b[0m Trial 13 finished with value: 0.9335650376781482 and parameters: {'max_depth': 18, 'max_features': 15, 'num_leaves': 158, 'feature_fraction': 0.7682102428478066, 'bagging_fraction': 0.9979173199638847, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:17,418]\u001b[0m Trial 14 finished with value: 0.9275623401587412 and parameters: {'max_depth': 12, 'max_features': 11, 'num_leaves': 88, 'feature_fraction': 0.5456158682173367, 'bagging_fraction': 0.8144420413146825, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:17,702]\u001b[0m Trial 15 finished with value: 0.9108440059596873 and parameters: {'max_depth': 16, 'max_features': 6, 'num_leaves': 204, 'feature_fraction': 0.8170485018534221, 'bagging_fraction': 0.6574179020884505, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 4 with value: 0.949848305889437.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:18,562]\u001b[0m Trial 16 finished with value: 0.9528518603068732 and parameters: {'max_depth': 13, 'max_features': 16, 'num_leaves': 139, 'feature_fraction': 0.9945197114375482, 'bagging_fraction': 0.9309199733267945, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:18,787]\u001b[0m Trial 17 finished with value: 0.9117036610609875 and parameters: {'max_depth': 7, 'max_features': 17, 'num_leaves': 128, 'feature_fraction': 0.6717218349537671, 'bagging_fraction': 0.8536959921187437, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:19,503]\u001b[0m Trial 18 finished with value: 0.9318446246466813 and parameters: {'max_depth': 12, 'max_features': 16, 'num_leaves': 54, 'feature_fraction': 0.858002350660516, 'bagging_fraction': 0.6894997050005841, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:19,858]\u001b[0m Trial 19 finished with value: 0.9279935462454741 and parameters: {'max_depth': 13, 'max_features': 11, 'num_leaves': 84, 'feature_fraction': 0.7117021297073862, 'bagging_fraction': 0.7899716790256659, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:20,500]\u001b[0m Trial 20 finished with value: 0.9395594639810577 and parameters: {'max_depth': 10, 'max_features': 15, 'num_leaves': 117, 'feature_fraction': 0.5153519855370203, 'bagging_fraction': 0.9067145192646725, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:21,111]\u001b[0m Trial 21 finished with value: 0.9378473221660881 and parameters: {'max_depth': 15, 'max_features': 12, 'num_leaves': 179, 'feature_fraction': 0.9932909413923354, 'bagging_fraction': 0.9509580408767395, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:21,851]\u001b[0m Trial 22 finished with value: 0.9494248196047681 and parameters: {'max_depth': 13, 'max_features': 2, 'num_leaves': 145, 'feature_fraction': 0.9961035383420636, 'bagging_fraction': 0.9099262746157556, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:22,541]\u001b[0m Trial 23 finished with value: 0.951568718920904 and parameters: {'max_depth': 12, 'max_features': 16, 'num_leaves': 143, 'feature_fraction': 0.8289227598586542, 'bagging_fraction': 0.8835466856923527, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:22,891]\u001b[0m Trial 24 finished with value: 0.9297067908893103 and parameters: {'max_depth': 10, 'max_features': 16, 'num_leaves': 142, 'feature_fraction': 0.8205842689428987, 'bagging_fraction': 0.8643990656063519, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:23,245]\u001b[0m Trial 25 finished with value: 0.9327103453067463 and parameters: {'max_depth': 12, 'max_features': 16, 'num_leaves': 110, 'feature_fraction': 0.864519237605445, 'bagging_fraction': 0.9957672018051754, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:23,632]\u001b[0m Trial 26 finished with value: 0.924134748042203 and parameters: {'max_depth': 16, 'max_features': 14, 'num_leaves': 34, 'feature_fraction': 0.732915824391824, 'bagging_fraction': 0.7841531938228592, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:23,754]\u001b[0m Trial 27 finished with value: 0.8645571756111602 and parameters: {'max_depth': 11, 'max_features': 17, 'num_leaves': 2, 'feature_fraction': 0.6167076809366089, 'bagging_fraction': 0.9464568239855482, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:24,432]\u001b[0m Trial 28 finished with value: 0.9412765685259258 and parameters: {'max_depth': 7, 'max_features': 14, 'num_leaves': 226, 'feature_fraction': 0.7674170302070336, 'bagging_fraction': 0.873463415130677, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:24,700]\u001b[0m Trial 29 finished with value: 0.9168472548935274 and parameters: {'max_depth': 13, 'max_features': 18, 'num_leaves': 74, 'feature_fraction': 0.6965315828835924, 'bagging_fraction': 0.6396629329900301, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:25,044]\u001b[0m Trial 30 finished with value: 0.9207027446101996 and parameters: {'max_depth': 2, 'max_features': 10, 'num_leaves': 99, 'feature_fraction': 0.8640379580887806, 'bagging_fraction': 0.5810487288526017, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:25,788]\u001b[0m Trial 31 finished with value: 0.9507107180629032 and parameters: {'max_depth': 13, 'max_features': 6, 'num_leaves': 149, 'feature_fraction': 0.9439060124731667, 'bagging_fraction': 0.8973548560238211, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:26,940]\u001b[0m Trial 32 finished with value: 0.9498494087183033 and parameters: {'max_depth': 15, 'max_features': 7, 'num_leaves': 140, 'feature_fraction': 0.9538136108590624, 'bagging_fraction': 0.9074871959413359, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:27,544]\u001b[0m Trial 33 finished with value: 0.936564180780119 and parameters: {'max_depth': 15, 'max_features': 7, 'num_leaves': 140, 'feature_fraction': 0.9432477967460466, 'bagging_fraction': 0.830445469698633, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:29,705]\u001b[0m Trial 34 finished with value: 0.9498466516461375 and parameters: {'max_depth': 16, 'max_features': 8, 'num_leaves': 179, 'feature_fraction': 0.9468345548910151, 'bagging_fraction': 0.8880285036926395, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:30,261]\u001b[0m Trial 35 finished with value: 0.9399928757255237 and parameters: {'max_depth': 18, 'max_features': 5, 'num_leaves': 181, 'feature_fraction': 0.9036154092221, 'bagging_fraction': 0.9240276768034088, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:31,281]\u001b[0m Trial 36 finished with value: 0.941277119940359 and parameters: {'max_depth': 14, 'max_features': 7, 'num_leaves': 151, 'feature_fraction': 0.9577425710541483, 'bagging_fraction': 0.7231091627632771, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:31,648]\u001b[0m Trial 37 finished with value: 0.9181331533516625 and parameters: {'max_depth': 12, 'max_features': 4, 'num_leaves': 132, 'feature_fraction': 0.912648478308266, 'bagging_fraction': 0.4166253484297415, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:32,641]\u001b[0m Trial 38 finished with value: 0.9502762034895711 and parameters: {'max_depth': 11, 'max_features': 8, 'num_leaves': 102, 'feature_fraction': 0.8772365842960432, 'bagging_fraction': 0.9678254018679046, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:33,144]\u001b[0m Trial 39 finished with value: 0.9365614237079533 and parameters: {'max_depth': 10, 'max_features': 9, 'num_leaves': 109, 'feature_fraction': 0.8697785781885631, 'bagging_fraction': 0.9737418601668959, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:34,439]\u001b[0m Trial 40 finished with value: 0.9511331015187056 and parameters: {'max_depth': 11, 'max_features': 4, 'num_leaves': 168, 'feature_fraction': 0.8324733439956671, 'bagging_fraction': 0.9594778536781555, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 16 with value: 0.9528518603068732.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:35,283]\u001b[0m Trial 41 finished with value: 0.9532786550781408 and parameters: {'max_depth': 11, 'max_features': 4, 'num_leaves': 167, 'feature_fraction': 0.8373083914324343, 'bagging_fraction': 0.9506802660810304, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:36,011]\u001b[0m Trial 42 finished with value: 0.9502773063184374 and parameters: {'max_depth': 9, 'max_features': 3, 'num_leaves': 165, 'feature_fraction': 0.7910883589714323, 'bagging_fraction': 0.9437334738917056, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:36,539]\u001b[0m Trial 43 finished with value: 0.9387086315106882 and parameters: {'max_depth': 11, 'max_features': 4, 'num_leaves': 190, 'feature_fraction': 0.8427527131958594, 'bagging_fraction': 0.8454995590488966, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:37,428]\u001b[0m Trial 44 finished with value: 0.9528529631357395 and parameters: {'max_depth': 9, 'max_features': 5, 'num_leaves': 129, 'feature_fraction': 0.9219938379600825, 'bagging_fraction': 0.9293819162459598, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:38,873]\u001b[0m Trial 45 finished with value: 0.9494182026315703 and parameters: {'max_depth': 9, 'max_features': 5, 'num_leaves': 126, 'feature_fraction': 0.8338269803958136, 'bagging_fraction': 0.9694690443746433, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:39,632]\u001b[0m Trial 46 finished with value: 0.9494187540460034 and parameters: {'max_depth': 8, 'max_features': 3, 'num_leaves': 170, 'feature_fraction': 0.7700201826994555, 'bagging_fraction': 0.9416722969542906, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:40,291]\u001b[0m Trial 47 finished with value: 0.9477099207176328 and parameters: {'max_depth': 9, 'max_features': 3, 'num_leaves': 193, 'feature_fraction': 0.8930556525883543, 'bagging_fraction': 0.9267315174433147, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:40,619]\u001b[0m Trial 48 finished with value: 0.9198491550676641 and parameters: {'max_depth': 6, 'max_features': 5, 'num_leaves': 158, 'feature_fraction': 0.9211699080232949, 'bagging_fraction': 0.8132601688567579, 'bagging_freq': 2, 'min_child_samples': 60}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:41,876]\u001b[0m Trial 49 finished with value: 0.9146989442619263 and parameters: {'max_depth': 12, 'max_features': 6, 'num_leaves': 123, 'feature_fraction': 0.7906628016839577, 'bagging_fraction': 0.5244852092219308, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:42,335]\u001b[0m Trial 50 finished with value: 0.9382779768383882 and parameters: {'max_depth': 8, 'max_features': 2, 'num_leaves': 215, 'feature_fraction': 0.9799965844762337, 'bagging_fraction': 0.9785832784988385, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 41 with value: 0.9532786550781408.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:43,154]\u001b[0m Trial 51 finished with value: 0.9532814121503067 and parameters: {'max_depth': 11, 'max_features': 6, 'num_leaves': 150, 'feature_fraction': 0.9748526732709393, 'bagging_fraction': 0.8917084094804456, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:43,702]\u001b[0m Trial 52 finished with value: 0.9331349344202815 and parameters: {'max_depth': 11, 'max_features': 4, 'num_leaves': 134, 'feature_fraction': 0.9741824011360934, 'bagging_fraction': 0.8819554732136567, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:44,656]\u001b[0m Trial 53 finished with value: 0.9528502060635736 and parameters: {'max_depth': 10, 'max_features': 3, 'num_leaves': 171, 'feature_fraction': 0.8920307567875262, 'bagging_fraction': 0.9287508592035283, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:46,099]\u001b[0m Trial 54 finished with value: 0.9489886507881367 and parameters: {'max_depth': 10, 'max_features': 3, 'num_leaves': 158, 'feature_fraction': 0.9291071219748873, 'bagging_fraction': 0.9211256301757939, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:46,697]\u001b[0m Trial 55 finished with value: 0.9399939785543899 and parameters: {'max_depth': 9, 'max_features': 13, 'num_leaves': 153, 'feature_fraction': 0.8981925627584133, 'bagging_fraction': 0.8399718628397294, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:46,972]\u001b[0m Trial 56 finished with value: 0.9138470089626902 and parameters: {'max_depth': 13, 'max_features': 5, 'num_leaves': 173, 'feature_fraction': 0.974728790965559, 'bagging_fraction': 0.7770235303951639, 'bagging_freq': 3, 'min_child_samples': 81}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:47,889]\u001b[0m Trial 57 finished with value: 0.9507074095763043 and parameters: {'max_depth': 10, 'max_features': 17, 'num_leaves': 190, 'feature_fraction': 0.8856742490523442, 'bagging_fraction': 0.9989597281356031, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:48,453]\u001b[0m Trial 58 finished with value: 0.9387058744385223 and parameters: {'max_depth': 7, 'max_features': 2, 'num_leaves': 136, 'feature_fraction': 0.9293003475688266, 'bagging_fraction': 0.8655533724672336, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:48,757]\u001b[0m Trial 59 finished with value: 0.9215640539547995 and parameters: {'max_depth': 14, 'max_features': 12, 'num_leaves': 122, 'feature_fraction': 0.9692549301101708, 'bagging_fraction': 0.9271818479119648, 'bagging_freq': 3, 'min_child_samples': 91}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:49,226]\u001b[0m Trial 60 finished with value: 0.9322791392200133 and parameters: {'max_depth': 8, 'max_features': 15, 'num_leaves': 110, 'feature_fraction': 0.9998632858961336, 'bagging_fraction': 0.8927150376532411, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:50,105]\u001b[0m Trial 61 finished with value: 0.953279206492574 and parameters: {'max_depth': 12, 'max_features': 4, 'num_leaves': 167, 'feature_fraction': 0.8363489230219957, 'bagging_fraction': 0.9569319233386867, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:51,589]\u001b[0m Trial 62 finished with value: 0.9481334070023015 and parameters: {'max_depth': 12, 'max_features': 3, 'num_leaves': 158, 'feature_fraction': 0.8472667893476035, 'bagging_fraction': 0.9527023916467169, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:52,491]\u001b[0m Trial 63 finished with value: 0.9498510629616028 and parameters: {'max_depth': 12, 'max_features': 6, 'num_leaves': 199, 'feature_fraction': 0.9268186546023828, 'bagging_fraction': 0.8103221700955907, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:53,119]\u001b[0m Trial 64 finished with value: 0.948565715917901 and parameters: {'max_depth': 10, 'max_features': 4, 'num_leaves': 183, 'feature_fraction': 0.8068780834042859, 'bagging_fraction': 0.9266449529074644, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:53,561]\u001b[0m Trial 65 finished with value: 0.93056810023391 and parameters: {'max_depth': 11, 'max_features': 5, 'num_leaves': 146, 'feature_fraction': 0.744392646944279, 'bagging_fraction': 0.8568787600753658, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:53,891]\u001b[0m Trial 66 finished with value: 0.9267054421296067 and parameters: {'max_depth': 14, 'max_features': 6, 'num_leaves': 168, 'feature_fraction': 0.8864183376769927, 'bagging_fraction': 0.9823619868222344, 'bagging_freq': 2, 'min_child_samples': 75}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:54,659]\u001b[0m Trial 67 finished with value: 0.9477066122310339 and parameters: {'max_depth': 11, 'max_features': 3, 'num_leaves': 88, 'feature_fraction': 0.9117194249270454, 'bagging_fraction': 0.8824149628801271, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:55,876]\u001b[0m Trial 68 finished with value: 0.950275652075138 and parameters: {'max_depth': 13, 'max_features': 5, 'num_leaves': 148, 'feature_fraction': 0.8518752260438289, 'bagging_fraction': 0.9087644865768413, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:56,532]\u001b[0m Trial 69 finished with value: 0.9194173975664978 and parameters: {'max_depth': 12, 'max_features': 16, 'num_leaves': 176, 'feature_fraction': 0.4087984216108368, 'bagging_fraction': 0.9581940567269225, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:57,070]\u001b[0m Trial 70 finished with value: 0.9361335261078191 and parameters: {'max_depth': 10, 'max_features': 2, 'num_leaves': 230, 'feature_fraction': 0.8173761929690807, 'bagging_fraction': 0.9017995599082861, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 51 with value: 0.9532814121503067.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:57,971]\u001b[0m Trial 71 finished with value: 0.9537071040927083 and parameters: {'max_depth': 11, 'max_features': 4, 'num_leaves': 163, 'feature_fraction': 0.8367766422418513, 'bagging_fraction': 0.9609811107904124, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:58,800]\u001b[0m Trial 72 finished with value: 0.9502767549040043 and parameters: {'max_depth': 12, 'max_features': 4, 'num_leaves': 161, 'feature_fraction': 0.8723088642738812, 'bagging_fraction': 0.9413891483770721, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:12:59,457]\u001b[0m Trial 73 finished with value: 0.9477071636454669 and parameters: {'max_depth': 9, 'max_features': 7, 'num_leaves': 139, 'feature_fraction': 0.7749889960547997, 'bagging_fraction': 0.9301823062360995, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:00,672]\u001b[0m Trial 74 finished with value: 0.9498499601327365 and parameters: {'max_depth': 10, 'max_features': 14, 'num_leaves': 132, 'feature_fraction': 0.9532668729110148, 'bagging_fraction': 0.981853485401343, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:01,271]\u001b[0m Trial 75 finished with value: 0.9442790201144957 and parameters: {'max_depth': 13, 'max_features': 4, 'num_leaves': 153, 'feature_fraction': 0.7457761993246107, 'bagging_fraction': 0.913923794621569, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:02,639]\u001b[0m Trial 76 finished with value: 0.9485613046024356 and parameters: {'max_depth': 11, 'max_features': 9, 'num_leaves': 117, 'feature_fraction': 0.8255327589759461, 'bagging_fraction': 0.962986115798443, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:03,380]\u001b[0m Trial 77 finished with value: 0.9494215111181692 and parameters: {'max_depth': 12, 'max_features': 10, 'num_leaves': 182, 'feature_fraction': 0.8044791910398874, 'bagging_fraction': 0.9990535929921341, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:04,370]\u001b[0m Trial 78 finished with value: 0.9511353071764382 and parameters: {'max_depth': 11, 'max_features': 3, 'num_leaves': 144, 'feature_fraction': 0.963049487199904, 'bagging_fraction': 0.8706833920563063, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:05,389]\u001b[0m Trial 79 finished with value: 0.9339896267916834 and parameters: {'max_depth': 10, 'max_features': 17, 'num_leaves': 163, 'feature_fraction': 0.9888661289599664, 'bagging_fraction': 0.6520702845634533, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:06,014]\u001b[0m Trial 80 finished with value: 0.9429958787285265 and parameters: {'max_depth': 14, 'max_features': 5, 'num_leaves': 173, 'feature_fraction': 0.8580183773263199, 'bagging_fraction': 0.8906266689893726, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:07,002]\u001b[0m Trial 81 finished with value: 0.9528529631357395 and parameters: {'max_depth': 11, 'max_features': 3, 'num_leaves': 144, 'feature_fraction': 0.9448995967410508, 'bagging_fraction': 0.9374797487748133, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:07,264]\u001b[0m Trial 82 finished with value: 0.9104183140172858 and parameters: {'max_depth': 13, 'max_features': 2, 'num_leaves': 154, 'feature_fraction': 0.4427867446170699, 'bagging_fraction': 0.9461648102162958, 'bagging_freq': 5, 'min_child_samples': 68}. Best is trial 71 with value: 0.9537071040927083.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:08,149]\u001b[0m Trial 83 finished with value: 0.9545673106084417 and parameters: {'max_depth': 12, 'max_features': 4, 'num_leaves': 141, 'feature_fraction': 0.9288308577537582, 'bagging_fraction': 0.9354933846451584, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 83 with value: 0.9545673106084417.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:09,981]\u001b[0m Trial 84 finished with value: 0.9545662077795755 and parameters: {'max_depth': 11, 'max_features': 4, 'num_leaves': 130, 'feature_fraction': 0.9454055408363973, 'bagging_fraction': 0.9363464214257355, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 83 with value: 0.9545673106084417.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:11,202]\u001b[0m Trial 85 finished with value: 0.944280122943362 and parameters: {'max_depth': 11, 'max_features': 4, 'num_leaves': 120, 'feature_fraction': 0.9394700455889956, 'bagging_fraction': 0.960310279459596, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 83 with value: 0.9545673106084417.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:13,487]\u001b[0m Trial 86 finished with value: 0.9558521062377103 and parameters: {'max_depth': 13, 'max_features': 6, 'num_leaves': 130, 'feature_fraction': 0.9858114243561329, 'bagging_fraction': 0.9799582532533058, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 86 with value: 0.9558521062377103.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:16,245]\u001b[0m Trial 87 finished with value: 0.9507052039185715 and parameters: {'max_depth': 11, 'max_features': 6, 'num_leaves': 115, 'feature_fraction': 0.9144851414065319, 'bagging_fraction': 0.9873370323737043, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 86 with value: 0.9558521062377103.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:17,472]\u001b[0m Trial 88 finished with value: 0.9532797579070073 and parameters: {'max_depth': 12, 'max_features': 6, 'num_leaves': 130, 'feature_fraction': 0.9358248911109259, 'bagging_fraction': 0.9645752179605432, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 86 with value: 0.9558521062377103.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:19,102]\u001b[0m Trial 89 finished with value: 0.9472754061443007 and parameters: {'max_depth': 12, 'max_features': 6, 'num_leaves': 127, 'feature_fraction': 0.9374912345663957, 'bagging_fraction': 0.9723857296977274, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 86 with value: 0.9558521062377103.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:19,876]\u001b[0m Trial 90 finished with value: 0.9511375128341709 and parameters: {'max_depth': 12, 'max_features': 7, 'num_leaves': 103, 'feature_fraction': 0.9860010724830526, 'bagging_fraction': 0.9524119814775108, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 86 with value: 0.9558521062377103.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:20,831]\u001b[0m Trial 91 finished with value: 0.9584244545684134 and parameters: {'max_depth': 13, 'max_features': 5, 'num_leaves': 131, 'feature_fraction': 0.9602930312450314, 'bagging_fraction': 0.9381379977950232, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:21,668]\u001b[0m Trial 92 finished with value: 0.9537093097504408 and parameters: {'max_depth': 13, 'max_features': 5, 'num_leaves': 128, 'feature_fraction': 0.9639426651417208, 'bagging_fraction': 0.913170181842434, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:22,572]\u001b[0m Trial 93 finished with value: 0.9541372073505751 and parameters: {'max_depth': 13, 'max_features': 5, 'num_leaves': 133, 'feature_fraction': 0.9678771455977957, 'bagging_fraction': 0.9743480344086968, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:23,447]\u001b[0m Trial 94 finished with value: 0.9541372073505751 and parameters: {'max_depth': 14, 'max_features': 6, 'num_leaves': 135, 'feature_fraction': 0.9632120027483504, 'bagging_fraction': 0.9743040566578957, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:24,303]\u001b[0m Trial 95 finished with value: 0.9545667591940085 and parameters: {'max_depth': 14, 'max_features': 6, 'num_leaves': 135, 'feature_fraction': 0.961487068625317, 'bagging_fraction': 0.986360962465632, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:25,149]\u001b[0m Trial 96 finished with value: 0.9545667591940085 and parameters: {'max_depth': 15, 'max_features': 7, 'num_leaves': 113, 'feature_fraction': 0.9659130047376537, 'bagging_fraction': 0.9864850801039386, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:25,741]\u001b[0m Trial 97 finished with value: 0.938277425423955 and parameters: {'max_depth': 15, 'max_features': 7, 'num_leaves': 111, 'feature_fraction': 0.9561023904298617, 'bagging_fraction': 0.9788051048029234, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:26,474]\u001b[0m Trial 98 finished with value: 0.9498527172049024 and parameters: {'max_depth': 17, 'max_features': 5, 'num_leaves': 94, 'feature_fraction': 0.9658570308233204, 'bagging_fraction': 0.9945932016427672, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n",
            "\u001b[32m[I 2022-03-16 11:13:27,313]\u001b[0m Trial 99 finished with value: 0.954568413437308 and parameters: {'max_depth': 15, 'max_features': 5, 'num_leaves': 138, 'feature_fraction': 0.9644565256705218, 'bagging_fraction': 0.98634123971004, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 91 with value: 0.9584244545684134.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenTrial(number=91, values=[0.9584244545684134], datetime_start=datetime.datetime(2022, 3, 16, 11, 13, 19, 878184), datetime_complete=datetime.datetime(2022, 3, 16, 11, 13, 20, 831317), params={'max_depth': 13, 'max_features': 5, 'num_leaves': 131, 'feature_fraction': 0.9602930312450314, 'bagging_fraction': 0.9381379977950232, 'bagging_freq': 6, 'min_child_samples': 16}, distributions={'max_depth': IntUniformDistribution(high=18, low=2, step=1), 'max_features': IntUniformDistribution(high=18, low=2, step=1), 'num_leaves': IntUniformDistribution(high=256, low=2, step=1), 'feature_fraction': UniformDistribution(high=1.0, low=0.4), 'bagging_fraction': UniformDistribution(high=1.0, low=0.4), 'bagging_freq': IntUniformDistribution(high=7, low=1, step=1), 'min_child_samples': IntUniformDistribution(high=100, low=5, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=91, state=TrialState.COMPLETE, value=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(study.best_params)"
      ],
      "metadata": {
        "id": "LjbRBsA5dkEH",
        "outputId": "44d8f9c7-8569-411a-8f01-fcd6d3701af8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 13, 'max_features': 5, 'num_leaves': 131, 'feature_fraction': 0.9602930312450314, 'bagging_fraction': 0.9381379977950232, 'bagging_freq': 6, 'min_child_samples': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "model = lgb.LGBMClassifier(random_state=17,**study.best_params)\n",
        "model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "xgb_pred = model.predict(X_test)\n",
        "accuracy_score(y_test, xgb_pred)"
      ],
      "metadata": {
        "id": "2aGpk-xPg1wH",
        "outputId": "55ff9a8d-a76e-4886-e38e-8e45edb48ce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.958"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ]
}